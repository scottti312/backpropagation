{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = pd.read_csv(\"data/training60000.csv\", header=None)\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = pd.read_csv(\"data/training60000_labels.csv\", header=None)\n",
    "y_train = np.eye(10)[y_train.astype('int32')].reshape(60000,10)\n",
    "X_test = pd.read_csv(\"data/testing10000.csv\", header=None)\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = pd.read_csv(\"data/testing10000_labels.csv\", header=None)\n",
    "y_test = np.eye(10)[y_test.astype('int32')].reshape(10000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 5\n",
    "plt.imshow(X_train[i].reshape(28,28), cmap='Greys')\n",
    "plt.show()\n",
    "print(y_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss: 84.63162650981336\n",
      "Epoch: 1\tLoss: 43.25464603256321\n",
      "Epoch: 2\tLoss: 34.83804665721932\n",
      "Epoch: 3\tLoss: 30.586131188074916\n",
      "Epoch: 4\tLoss: 27.90471175689956\n",
      "Epoch: 5\tLoss: 26.048141205381235\n",
      "Epoch: 6\tLoss: 24.45487276141241\n",
      "Epoch: 7\tLoss: 23.343754121957076\n",
      "Epoch: 8\tLoss: 22.200044389914652\n",
      "Epoch: 9\tLoss: 21.281110611691727\n",
      "Epoch: 10\tLoss: 20.56312846556491\n",
      "Epoch: 11\tLoss: 19.918498981492572\n",
      "Epoch: 12\tLoss: 19.19128517358737\n",
      "Epoch: 13\tLoss: 18.60025549031518\n",
      "Epoch: 14\tLoss: 18.09273269270078\n",
      "Epoch: 15\tLoss: 17.70007741952993\n",
      "Epoch: 16\tLoss: 17.221519945080136\n",
      "Epoch: 17\tLoss: 16.904776328974553\n",
      "Epoch: 18\tLoss: 16.5794761404037\n",
      "Epoch: 19\tLoss: 16.19594214685204\n",
      "Epoch: 20\tLoss: 15.796416811861972\n",
      "Epoch: 21\tLoss: 15.49791448880816\n",
      "Epoch: 22\tLoss: 15.176748413764175\n",
      "Epoch: 23\tLoss: 14.867398280313697\n",
      "Epoch: 24\tLoss: 14.649752292691588\n",
      "Epoch: 25\tLoss: 14.412183156942149\n",
      "Epoch: 26\tLoss: 14.173653893136832\n",
      "Epoch: 27\tLoss: 13.923566916376316\n",
      "Epoch: 28\tLoss: 13.584958562272998\n",
      "Epoch: 29\tLoss: 13.396865366492833\n",
      "====Results\n",
      "Network properties: Input: 784, Batch Size: 64, Output: 10\n",
      "Correct classification: 9057\n",
      "Incorrect classification: 943\n",
      "Accuracy: 90.57%\n"
     ]
    }
   ],
   "source": [
    "class DeepNeuralNetwork:\n",
    "    def __init__(self, X_train, y_train, learn_rate = 0.0001, epochs = 30, batch_size = 64):\n",
    "        self.X_train = X_train \n",
    "        self.y_train = y_train\n",
    "        self.learn_rate = learn_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.batch_x = self.X_train[:batch_size]\n",
    "        self.batch_y = self.y_train[:batch_size]\n",
    "        \n",
    "        np.random.seed(14)\n",
    "        layer1_neurons = 784\n",
    "        layer2_neurons = 392\n",
    "        \n",
    "        self.weight1 = np.random.randn(self.X_train.shape[1], layer1_neurons)\n",
    "        self.bias1 = np.random.randn(layer1_neurons)\n",
    "        self.weight2 = np.random.randn(layer1_neurons, layer2_neurons)\n",
    "        self.bias2 = np.random.randn(layer2_neurons)\n",
    "        self.weight3 = np.random.randn(layer2_neurons, self.batch_y.shape[1])\n",
    "        self.bias3 = np.random.randn(self.weight3.shape[1])\n",
    "        \n",
    "    def forwardpass(self):\n",
    "        self.z1 = self.batch_x.dot(self.weight1) + self.bias1\n",
    "        # ReLU layer\n",
    "        self.layer1 = np.maximum(0, self.z1)\n",
    "\n",
    "        self.z2 = self.layer1.dot(self.weight2) + self.bias2\n",
    "        # ReLU layer\n",
    "        self.layer2 = np.maximum(0, self.z2)\n",
    "        \n",
    "        self.z3 = self.layer2.dot(self.weight3) + self.bias3\n",
    "        z3 = self.z3 - np.max(self.z3, axis = 1).reshape(self.z3.shape[0], 1)\n",
    "        # Softmax layer\n",
    "        self.layer3 = np.exp(z3) / np.sum(np.exp(z3), axis = 1).reshape(z3.shape[0], 1)\n",
    "        self.error = self.layer3 - self.batch_y\n",
    "\n",
    "    def backpropagate(self):\n",
    "        cost = (1 / self.batch_size) * self.error\n",
    "        dweight3 = np.dot(cost.T, self.layer2).T\n",
    "        dbias3 = np.sum(cost,axis = 0)\n",
    "        self.weight3 = self.weight3 - self.learn_rate * dweight3\n",
    "        self.bias3 = self.bias3 - self.learn_rate * dbias3\n",
    "        \n",
    "        dweight2 = np.dot((np.dot((cost), self.weight3.T) \n",
    "                            * (self.z2 > 0)).T, self.layer1).T\n",
    "        dbias2 = np.sum(np.dot((cost),self.weight3.T) \n",
    "                            * (self.z2 > 0),axis = 0)\n",
    "        self.weight2 = self.weight2 - self.learn_rate * dweight2\n",
    "        self.bias2 = self.bias2 - self.learn_rate * dbias2\n",
    "\n",
    "        dweight1 = np.dot((np.dot(np.dot((cost), self.weight3.T)\n",
    "                            * (self.z2 > 0),self.weight2.T) * (self.z1 > 1)).T, self.batch_x).T\n",
    "        dbias1 = np.sum((np.dot(np.dot((cost), self.weight3.T) \n",
    "                            * (self.z2 > 0), self.weight2.T) * (self.z1 > 1)), axis = 0)\n",
    "        self.weight1 = self.weight1 - self.learn_rate * dweight1\n",
    "        self.bias1 = self.bias1 - self.learn_rate * dbias1\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            loss = 0\n",
    "            for batch_size in range(self.X_train.shape[0] // self.batch_size - 1):\n",
    "                a = batch_size * self.batch_size\n",
    "                b = (batch_size + 1) * self.batch_size\n",
    "                self.batch_x = self.X_train[a:b]\n",
    "                self.batch_y = self.y_train[a:b]\n",
    "                self.forwardpass()\n",
    "                self.backpropagate()\n",
    "                loss += np.mean(self.error ** 2)\n",
    "\n",
    "            print('Epoch: {}\\tLoss: {}'.format(epoch, loss))\n",
    "        \n",
    "    def results(self,xtest,ytest):\n",
    "        self.batch_x = xtest\n",
    "        self.batch_y = ytest\n",
    "        self.forwardpass()\n",
    "        correct = np.count_nonzero(np.argmax(self.layer3,axis=1) == np.argmax(self.batch_y, axis=1))\n",
    "        incorrect = self.batch_x.shape[0] - correct\n",
    "        accuracy = correct / self.batch_x.shape[0]\n",
    "        print(\"====Results\\nNetwork properties: Input: {0}, Batch Size: {1}, Output: {2}\\nCorrect classification: {3}\\nIncorrect classification: {4}\\nAccuracy: {5}%\"\n",
    "                .format(X_train.shape[1], self.batch_size, self.batch_y.shape[1], correct, incorrect, round(100*accuracy,2)))\n",
    "\n",
    "\n",
    "dnn = DeepNeuralNetwork(X_train, y_train) \n",
    "dnn.train()\n",
    "dnn.results(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0661617b85a873d2b1e7e492c37ac824eb06450b9a7a1e234e76f5a79ca18d3f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
